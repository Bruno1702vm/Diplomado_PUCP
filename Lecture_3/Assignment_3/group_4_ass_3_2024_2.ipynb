{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3\n",
    "\n",
    "#### Group 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n",
      "Requirement already satisfied: savReaderWriter in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.4.2)\n"
     ]
    }
   ],
   "source": [
    "## First, install pyreadstat and savReaderWriter packages\n",
    "!pip install pyreadstat\n",
    "!pip install savReaderWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**\n",
    "\n",
    "Done by: Vania Aspilcueta S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling database according the indications above and the variables and values. \n",
    "#This is the code for the first file: rec_1\n",
    "rec_1, file_1 = pyreadstat.read_sav( '../../_data/endes/2019/REC0111.sav' )\n",
    "\n",
    "var_labels1 = file_1.column_names_to_labels\n",
    "\n",
    "value_labels1 = file_1.variable_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the code for the second file: rec_2\n",
    "rec_2, file_2 = pyreadstat.read_sav( '../../_data/endes/2019/RE223132.sav' )\n",
    "\n",
    "var_labels2 = file_2.column_names_to_labels\n",
    "\n",
    "value_labels2 = file_2.variable_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the code for the third file: rec_3\n",
    "rec_3, file_3 = pyreadstat.read_sav( '../../_data/endes/2019/RE516171.sav' )\n",
    "\n",
    "var_labels3 = file_3.column_names_to_labels\n",
    "\n",
    "value_labels3 = file_3.variable_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyreadstat._readstat_parser.metadata_container at 0x130c67b6030>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the created variable \"file_1\"\n",
    "file_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID1': 'Año',\n",
       " 'HHID': 'Identificación Cuestionario del Hogar',\n",
       " 'CASEID': 'Identificación Cuestionario Individual',\n",
       " 'V001': 'Conglomerado',\n",
       " 'V002': 'Número de vivienda',\n",
       " 'V003': 'Número de línea de entrevistada',\n",
       " 'V004': 'Unidad de área final',\n",
       " 'V007': 'Año de la entrevista',\n",
       " 'V008': 'Fecha de la entrevista, Codificación centenaria de meses (CMC)',\n",
       " 'V009': 'Mes de nacimiento de la entrevistada',\n",
       " 'V010': 'Año de nacimiento de la entrevistada',\n",
       " 'V011': 'Fecha de nacimiento, Codificación centenaria de meses (CMC)',\n",
       " 'V012': 'Edad actual - entrevistada',\n",
       " 'V013': 'Edad actual por grupos de 5 años',\n",
       " 'V014': 'Integridad de la información para la fecha de nacimiento',\n",
       " 'V015': 'Resultado entrevista individual',\n",
       " 'V017': 'Inicio del calendario, Codificación centenaria de mesesl CMC',\n",
       " 'V018': 'Columna del mes de la entrevista',\n",
       " 'V019': 'Duración del calendario',\n",
       " 'V019A': 'Número de columnas de calendario',\n",
       " 'V020': 'Muestra alguna vez casada',\n",
       " 'V021': 'Unidad de muestreo primario - conglomerado',\n",
       " 'V023': 'Dominio de ejemplo - Departamento',\n",
       " 'V024': 'Región',\n",
       " 'V025': 'Tipo de lugar de residencia',\n",
       " 'V026': 'El lugar de residencia en el que se entrevistó - De Facto',\n",
       " 'V027': 'Número de visitas',\n",
       " 'V028': 'Identificación del entrevistador',\n",
       " 'V029': 'Identificador del digitador',\n",
       " 'V030': 'Supervisor de campo',\n",
       " 'V031': 'Editor de campo',\n",
       " 'V032': 'Editor de la oficina',\n",
       " 'V033': 'Selección final del área de probabilidad',\n",
       " 'V034': 'Número de orden del esposo',\n",
       " 'V040': 'Altitud del conglomerado en metros',\n",
       " 'V042': 'Selección de hogar para hemoglobina',\n",
       " 'V043': 'Selección para módulo de estatus de mujeres',\n",
       " 'V044': 'Selección para módulo de violencia domestica',\n",
       " 'V000': 'Código y fase del país',\n",
       " 'Q105DD': 'Dia de nacimeinto de la entrevistada',\n",
       " 'V101': 'Región',\n",
       " 'V102': 'Tipo de lugar de residencia',\n",
       " 'V103': 'Lugar de residencia de la infancia',\n",
       " 'V104': 'Cuanto tiempo tiene viviendo continuamente en el lugar de residencia actual',\n",
       " 'V105': 'Tipo de lugar de residencia anteriormente',\n",
       " 'V106': 'Nivel educativo más alto',\n",
       " 'V107': 'Año/grado de educación más alto aprobado',\n",
       " 'V113': 'Fuente principal de abasteciemiento de agua potable que utilizan en su hogar para tomar o beber',\n",
       " 'V115': 'Tiempo para llegar a la fuente de agua',\n",
       " 'V116': 'Tipo de instalación sanitaria',\n",
       " 'V119': 'En su hogar tiene: electricidad',\n",
       " 'V120': 'En su hogar tiene: radio',\n",
       " 'V121': 'En su hogar tiene: televisión',\n",
       " 'V122': 'En su hogar tiene: refrigerador',\n",
       " 'V123': 'En su hogar tiene: bicicleta',\n",
       " 'V124': 'En su hogar tiene: motocicleta/motocar',\n",
       " 'V125': 'En su hogar tiene: coche/camión',\n",
       " 'V127': 'Material predominante del piso de la vivienda',\n",
       " 'V128': 'Material predominante de las paredes exteriores de la vivienda',\n",
       " 'V129': 'Material predominante del techo de la vivienda',\n",
       " 'V130': 'Religión',\n",
       " 'V131': 'Etnicidad',\n",
       " 'V133': 'Educación en años simples',\n",
       " 'V134': 'El lugar en el que se realizó la entrevista  De-facto',\n",
       " 'V135': 'Residente habitual o visitante',\n",
       " 'V136': 'Número de miembros del hogar',\n",
       " 'V137': 'Número de niños de 6 años de edad',\n",
       " 'V138': 'Número de mujeres de 15 a 49 años de edad elegibles en el hogar',\n",
       " 'V139': 'Región, residencia habitual De-jure',\n",
       " 'V140': 'Tipo de área de residencia De-jure',\n",
       " 'V141': 'Lugar de residencia De-jure',\n",
       " 'V149': 'Logro educativo',\n",
       " 'V150': 'Relación con el jefe del hogar',\n",
       " 'V151': 'Sexo del Jefe del Hogar',\n",
       " 'V152': 'Edad del jefe del hogar',\n",
       " 'V153': 'En su hogar tiene: teléfono',\n",
       " 'AWFACTT': 'Factor todas las mujeres - total',\n",
       " 'AWFACTU': 'Factor todas las mujeres - urbano/rural',\n",
       " 'AWFACTR': 'Factor todas las mujeres - regional',\n",
       " 'AWFACTE': 'Factor todas las mujeres - educación',\n",
       " 'AWFACTW': 'Factor todas las mujeres - índice de riqueza',\n",
       " 'V155': 'Alfabetización',\n",
       " 'V156': 'Alguna vez participó en un programa de alfabetización (no incluyendo la escuela primaria)',\n",
       " 'V157': 'Frecuencia de lectura de un periódico o revista',\n",
       " 'V158': 'Frecuencia de escuchar radio',\n",
       " 'V159': 'Frecuencia de ver televisión',\n",
       " 'V160': 'Baño compartido con otros hogares',\n",
       " 'V161': 'Tipo de combustible para cocinar',\n",
       " 'V166': 'Resultados de la prueba del yodo en la sal',\n",
       " 'V167': 'Número de viajes en los últimos 12 meses',\n",
       " 'V168': 'Afuera más de un mes en los últimos 12 meses',\n",
       " 'ML101': 'Tipo de mosquitero que utilizo para dormir última noche',\n",
       " 'QD333_1': 'Alguna dificultad o limitación permanente para ver, aún usando anteojos',\n",
       " 'QD333_2': 'Alguna dificultad o limitación permanente para oir, aún usando audífonos',\n",
       " 'QD333_3': 'Alguna dificultad o limitación permanente para hablar o comunicarse, aún usando la lengua de señas u otro',\n",
       " 'QD333_4': 'Alguna dificultad o limitación permanente para moverse o caminar para usar brazos y/o piernas',\n",
       " 'QD333_5': 'Alguna dificultad o limitación permanente para entender o aprender (concentrarse y recordarse)',\n",
       " 'QD333_6': 'Alguna dificultad o limitación permanente para relacionarse con los demás, por sus pensamientos, sentimientos, emociones o conductas',\n",
       " 'UBIGEO': 'Código de Ubicación Gegráfica',\n",
       " 'V022': 'Estratos',\n",
       " 'V005': 'Factor de ponderacion',\n",
       " 'V190': 'Índice de riqueza',\n",
       " 'V191': 'Factor de puntuación del índice de riqueza (5 decimales)',\n",
       " 'mujeres12a49': 'Mujeres de 12 a 49 años de edad',\n",
       " 'NCONGLOME': 'Número de Conglomerado (proveniente del marco)'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To verify the labels of variable1\n",
    "var_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set. Check if all the columns are in the dataset. Make a code that check the columns that are not included. Please, reporte them.\n",
    "\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**\n",
    "\n",
    "Done by: Vania Aspilcueta S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the columns for the dataframes required\n",
    "#repeating the code for all the dataframes\n",
    "rec1_1 = rec_1.loc[ : ,['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']]\n",
    "rec2_1 = rec_2.loc[ : ,['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']]\n",
    "rec3_1 = rec_3.loc[ : ,['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relabelling the dataframe rec1_1 to new_columns_1\n",
    "new_columns_1 = rec1_1.columns.values \n",
    "\n",
    "#Updating the variables and value labels objects\n",
    "new_value_labels1 = { column:value for ( column, value ) in value_labels1.items() if column in new_columns_1 } \n",
    "new_var_labels1 = { column:value for ( column, value ) in var_labels1.items() if column in new_columns_1 }\n",
    "\n",
    "#Replicating the previous code\n",
    "new_columns_2 = rec2_1.columns.values\n",
    "new_value_labels2 = { column:value for ( column, value ) in value_labels2.items() if column in new_columns_2 }\n",
    "new_var_labels2 = { column:value for ( column, value ) in var_labels2.items() if column in new_columns_2 }\n",
    "\n",
    "#Replicating the previous code\n",
    "new_columns_3 = rec3_1.columns.values\n",
    "new_value_labels3 = { column:value for ( column, value ) in value_labels3.items() if column in new_columns_3 }\n",
    "new_var_labels3 = { column:value for ( column, value ) in var_labels3.items() if column in new_columns_3 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 22\n"
     ]
    }
   ],
   "source": [
    "print(len(new_value_labels1),len(new_value_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_value_labels3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CASEID V000  V001  V002  V003  V004    V007    V008  V009  \\\n",
      "0        000100201  2  PE6   1.0   2.0   2.0   1.0  2019.0  1434.0   4.0   \n",
      "1        000100201  3  PE6   1.0   2.0   3.0   1.0  2019.0  1434.0   1.0   \n",
      "2        000102801  2  PE6   1.0  28.0   2.0   1.0  2019.0  1434.0   6.0   \n",
      "3        000102801  6  PE6   1.0  28.0   6.0   1.0  2019.0  1434.0   3.0   \n",
      "4        000104801  2  PE6   1.0  48.0   2.0   1.0  2019.0  1434.0   5.0   \n",
      "\n",
      "     V010  ...  V102  V120  V121  V122  V123  V124  V125  V127  V133  year  \n",
      "0  1986.0  ...   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0  16.0  2019  \n",
      "1  2007.0  ...   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0   6.0  2019  \n",
      "2  1983.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0  16.0  2019  \n",
      "3  1970.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0   4.0  2019  \n",
      "4  1991.0  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0  34.0   1.0  2019  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "{'CASEID': 'Identificación Cuestionario Individual', 'V001': 'Conglomerado', 'V002': 'Número de vivienda', 'V003': 'Número de línea de entrevistada', 'V004': 'Unidad de área final', 'V007': 'Año de la entrevista', 'V008': 'Fecha de la entrevista, Codificación centenaria de meses (CMC)', 'V009': 'Mes de nacimiento de la entrevistada', 'V010': 'Año de nacimiento de la entrevistada', 'V011': 'Fecha de nacimiento, Codificación centenaria de meses (CMC)', 'V012': 'Edad actual - entrevistada', 'V024': 'Región', 'V000': 'Código y fase del país', 'V102': 'Tipo de lugar de residencia', 'V120': 'En su hogar tiene: radio', 'V121': 'En su hogar tiene: televisión', 'V122': 'En su hogar tiene: refrigerador', 'V123': 'En su hogar tiene: bicicleta', 'V124': 'En su hogar tiene: motocicleta/motocar', 'V125': 'En su hogar tiene: coche/camión', 'V127': 'Material predominante del piso de la vivienda', 'V133': 'Educación en años simples', 'year': 'Year of the survey'}\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# First, we load the .sav file\n",
    "rec_1, file_1 = pyreadstat.read_sav('../../_data/endes/2019/REC0111.sav')\n",
    "\n",
    "# Second, we create the DataFrame rec1_1 by selecting the required columns from rec_1 and making a copy\n",
    "rec1_1 = rec_1[['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']].copy()\n",
    "\n",
    "# Third, we define new_var_labels1 if it is not already defined\n",
    "new_var_labels1 = {column: value for column, value in file_1.column_names_to_labels.items() if column in rec1_1.columns}\n",
    "\n",
    "# Fourth, we add a new column 'year' with the value 2019 to rec1_1 using loc\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# Fifth, we add a new key 'year' with the value 'Year of the survey' to the new_var_labels1 dictionary\n",
    "new_var_labels1.update({'year': \"Year of the survey\"})\n",
    "\n",
    "# Sixth, we display the first few rows of rec1_1 to ensure the 'year' column is added\n",
    "print(rec1_1.head())\n",
    "\n",
    "# Finally, we display new_var_labels1 to ensure the 'year' label is added\n",
    "print(new_var_labels1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CASEID V000  V001  V002  V003  V004    V007    V008  V009  \\\n",
      "0        000100201  2  PE6   1.0   2.0   2.0   1.0  2019.0  1434.0   4.0   \n",
      "1        000100201  3  PE6   1.0   2.0   3.0   1.0  2019.0  1434.0   1.0   \n",
      "2        000102801  2  PE6   1.0  28.0   2.0   1.0  2019.0  1434.0   6.0   \n",
      "3        000102801  6  PE6   1.0  28.0   6.0   1.0  2019.0  1434.0   3.0   \n",
      "4        000104801  2  PE6   1.0  48.0   2.0   1.0  2019.0  1434.0   5.0   \n",
      "\n",
      "     V010  ...  V102  V120  V121  V122  V123  V124  V125  V127  V133  year  \n",
      "0  1986.0  ...   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0  16.0  2019  \n",
      "1  2007.0  ...   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0   6.0  2019  \n",
      "2  1983.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0  16.0  2019  \n",
      "3  1970.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0   4.0  2019  \n",
      "4  1991.0  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0  34.0   1.0  2019  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "{'CASEID': 'Identificación Cuestionario Individual', 'V000': 'Código y fase del país', 'V001': 'Conglomerado', 'V002': 'Número de vivienda', 'V003': 'Número de línea de entrevistada', 'V004': 'Unidad de área final', 'V007': 'Año de la entrevista', 'V008': 'Fecha de la entrevista, Codificación centenaria de meses (CMC)', 'V009': 'Mes de nacimiento de la entrevistada', 'V010': 'Año de nacimiento de la entrevistada', 'V011': 'Fecha de nacimiento, Codificación centenaria de meses (CMC)', 'V012': 'Edad actual - entrevistada', 'V024': 'Región', 'V102': 'Tipo de lugar de residencia', 'V120': 'En su hogar tiene: radio', 'V121': 'En su hogar tiene: televisión', 'V122': 'En su hogar tiene: refrigerador', 'V123': 'En su hogar tiene: bicicleta', 'V124': 'En su hogar tiene: motocicleta/motocar', 'V125': 'En su hogar tiene: coche/camión', 'V127': 'Material predominante del piso de la vivienda', 'V133': 'Educación en años simples', 'year': 'Year of the survey'}\n",
      "               CASEID V000  V001   V002  V003  V004    V007    V008  V009  \\\n",
      "0        000100201  2  PE6   1.0    2.0   2.0   1.0  2019.0  1434.0   4.0   \n",
      "1        000102801  2  PE6   1.0   28.0   2.0   1.0  2019.0  1434.0   6.0   \n",
      "2        000102801  6  PE6   1.0   28.0   6.0   1.0  2019.0  1434.0   3.0   \n",
      "3        000104801  2  PE6   1.0   48.0   2.0   1.0  2019.0  1434.0   5.0   \n",
      "4        000113601  2  PE6   1.0  136.0   2.0   1.0  2019.0  1434.0  11.0   \n",
      "\n",
      "     V010  ...    V508    V509  V510  V511  V512  V513  V525  V613  V714  V715  \n",
      "0  1986.0  ...  2008.0  1297.0   1.0  21.0  11.0   3.0  17.0   2.0   1.0  11.0  \n",
      "1  1983.0  ...  2011.0  1344.0   1.0  28.0   7.0   2.0  18.0   3.0   1.0  14.0  \n",
      "2  1970.0  ...  1984.0  1016.0   5.0  14.0  34.0   7.0  14.0   0.0   0.0   6.0  \n",
      "3  1991.0  ...  2009.0  1320.0   1.0  18.0   9.0   2.0  15.0   2.0   0.0   6.0  \n",
      "4  1988.0  ...  2005.0  1272.0   1.0  17.0  13.0   3.0  15.0   2.0   1.0  16.0  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "# First, we load the .sav files for rec_1, rec_2, and rec_3\n",
    "import pandas as pd  # this is to ensure pandas is imported\n",
    "rec_1, file_1 = pyreadstat.read_sav('../../_data/endes/2019/REC0111.sav')\n",
    "rec_2, file_2 = pyreadstat.read_sav('../../_data/endes/2019/RE223132.sav')\n",
    "rec_3, file_3 = pyreadstat.read_sav('../../_data/endes/2019/RE516171.sav')\n",
    "\n",
    "# Second, we create the DataFrames rec1_1, rec2_1, and rec3_1 selecting the required columns and making copies\n",
    "rec1_1 = rec_1[['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']].copy()\n",
    "rec2_1 = rec_2[['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']].copy()\n",
    "rec3_1 = rec_3[['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']].copy()\n",
    "\n",
    "# Third, we create new variable labels dictionaries for the new DataFrames\n",
    "new_var_labels1 = {column: file_1.column_names_to_labels[column] for column in rec1_1.columns}\n",
    "new_var_labels2 = {column: file_2.column_names_to_labels[column] for column in rec2_1.columns}\n",
    "new_var_labels3 = {column: file_3.column_names_to_labels[column] for column in rec3_1.columns}\n",
    "\n",
    "# Fourth, we add a new column 'year' with the value 2019 to rec1_1 DataFrame\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# Fifth, we update the variable labels dictionary new_var_labels1, adding a new key 'year' with the value 'Year of the survey'\n",
    "new_var_labels1.update({'year': 'Year of the survey'})\n",
    "\n",
    "# Sixth, we display the first few rows of rec1_1 to ensure the 'year' column is added\n",
    "print(rec1_1.head())\n",
    "\n",
    "# Seventh, we display new_var_labels1 to ensure the 'year' label is added\n",
    "print(new_var_labels1)\n",
    "\n",
    "# Eighth, we merge rec1_1, rec2_1, and rec3_1 using CASEID. We name this new object as endes_2019\n",
    "endes_2019 = pd.merge(pd.merge(rec1_1, rec2_1, on='CASEID'), rec3_1, on='CASEID')\n",
    "\n",
    "# Finally, we display the first few rows of endes_2019 to ensure the merge was successful\n",
    "print(endes_2019.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
