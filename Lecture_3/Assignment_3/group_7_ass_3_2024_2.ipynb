{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyreadstat\n",
      "  Downloading pyreadstat-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n",
      "Downloading pyreadstat-1.2.7-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.4 MB 656.4 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.2/2.4 MB 1.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.7/2.4 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.4/2.4 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.5/2.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.9/2.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.2/2.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 5.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pyreadstat\n",
      "Successfully installed pyreadstat-1.2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set. Check if all the columns are in the dataset. Make a code that check the columns that are not included. Please, reporte them.\n",
    "\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pyreadstat._readstat_parser.metadata_container'>\n"
     ]
    }
   ],
   "source": [
    "#### Solution 1:\n",
    "# 1.1 We import \"REC0111.sav\", \"RE223132.sav\", \"RE516171.sav\" files using dots. Then we read the SPSS file.\n",
    "rec_1,meta1 = pyreadstat.read_sav('../../_data/endes/2019/REC0111.sav')\n",
    "rec_2,meta2 = pyreadstat.read_sav('../../_data/endes/2019/RE223132.sav')\n",
    "rec_3,meta3 = pyreadstat.read_sav('../../_data/endes/2019/RE516171.sav')\n",
    "\n",
    "# Note: ENDES files are characterized by the storage of two objects: dataframe y metadata\n",
    "print(type(rec_1))\n",
    "print(type(meta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Now we get labels from containers of metadata (meta1, meta2 and meta3)\n",
    "# For rec1:\n",
    "var_labels1   = meta1.column_names_to_labels      # extract variable labels\n",
    "value_labels1 = meta1.variable_value_labels     # extract value labels of each variable\n",
    "# For rec2:\n",
    "var_labels2   = meta2.column_names_to_labels\n",
    "value_labels2 = meta2.variable_value_labels\n",
    "# For rec3:\n",
    "var_labels3   = meta3.column_names_to_labels\n",
    "value_labels3 = meta3.variable_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution 2:\n",
    "# 2.1 We select the columns of our interest\n",
    "rec1_1 = rec_1.loc[:,[\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \n",
    "                      \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\"]]\n",
    "rec2_1 = rec_2.loc[:,[\"CASEID\", \"V201\", \"V218\", \"V301\", \"V302\", \"V323\", \"V323A\", \"V325A\", \"V326\", \"V327\", \"V337\", \n",
    "                      \"V359\", \"V360\", \"V361\", \"V362\", \"V363\", \"V364\", \"V367\", \"V372\", \"V372A\", \"V375A\", \"V376\", \n",
    "                      \"V376A\", \"V379\", \"V380\"]]\n",
    "rec3_1 = rec_3.loc[:,[\"CASEID\", \"V501\", \"V502\", \"V503\", \"V504\", \"V505\", \"V506\", \"V507\", \"V508\", \"V509\", \"V510\",\n",
    "                      \"V511\", \"V512\", \"V513\", \"V525\", \"V613\", \"V714\", \"V715\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>...</th>\n",
       "      <th>V024</th>\n",
       "      <th>V102</th>\n",
       "      <th>V120</th>\n",
       "      <th>V121</th>\n",
       "      <th>V122</th>\n",
       "      <th>V123</th>\n",
       "      <th>V124</th>\n",
       "      <th>V125</th>\n",
       "      <th>V127</th>\n",
       "      <th>V133</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000100201  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000102801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000102801  6</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CASEID V000  V001  V002  V003  V004    V007    V008  V009  \\\n",
       "0        000100201  2  PE6   1.0   2.0   2.0   1.0  2019.0  1434.0   4.0   \n",
       "1        000100201  3  PE6   1.0   2.0   3.0   1.0  2019.0  1434.0   1.0   \n",
       "2        000102801  2  PE6   1.0  28.0   2.0   1.0  2019.0  1434.0   6.0   \n",
       "3        000102801  6  PE6   1.0  28.0   6.0   1.0  2019.0  1434.0   3.0   \n",
       "4        000104801  2  PE6   1.0  48.0   2.0   1.0  2019.0  1434.0   5.0   \n",
       "\n",
       "     V010  ...  V024  V102  V120  V121  V122  V123  V124  V125  V127  V133  \n",
       "0  1986.0  ...   1.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0  16.0  \n",
       "1  2007.0  ...   1.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0   6.0  \n",
       "2  1983.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0  16.0  \n",
       "3  1970.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0   4.0  \n",
       "4  1991.0  ...   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  34.0   1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec1_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rec1_1: True\n",
      "For rec2_1: True\n",
      "For rec3_1: True\n"
     ]
    }
   ],
   "source": [
    "# We check if all the columns are in the dataset:\n",
    "print(\"For rec1_1:\", list(rec1_1.columns) == [\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \n",
    "                      \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\"])\n",
    "print(\"For rec2_1:\", list(rec2_1.columns) == [\"CASEID\", \"V201\", \"V218\", \"V301\", \"V302\", \"V323\", \"V323A\", \"V325A\", \"V326\", \"V327\", \"V337\", \n",
    "                      \"V359\", \"V360\", \"V361\", \"V362\", \"V363\", \"V364\", \"V367\", \"V372\", \"V372A\", \"V375A\", \"V376\", \n",
    "                      \"V376A\", \"V379\", \"V380\"])\n",
    "print(\"For rec3_1:\", list(rec3_1.columns) == [\"CASEID\", \"V501\", \"V502\", \"V503\", \"V504\", \"V505\", \"V506\", \"V507\", \"V508\", \"V509\", \"V510\",\n",
    "                      \"V511\", \"V512\", \"V513\", \"V525\", \"V613\", \"V714\", \"V715\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID1', 'HHID', 'V013', 'V014', 'V015', 'V017', 'V018', 'V019', 'V019A', 'V020', 'V021', 'V023', 'V025', 'V026', 'V027', 'V028', 'V029', 'V030', 'V031', 'V032', 'V033', 'V034', 'V040', 'V042', 'V043', 'V044', 'Q105DD', 'V101', 'V103', 'V104', 'V105', 'V106', 'V107', 'V113', 'V115', 'V116', 'V119', 'V128', 'V129', 'V130', 'V131', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V149', 'V150', 'V151', 'V152', 'V153', 'AWFACTT', 'AWFACTU', 'AWFACTR', 'AWFACTE', 'AWFACTW', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V166', 'V167', 'V168', 'ML101', 'QD333_1', 'QD333_2', 'QD333_3', 'QD333_4', 'QD333_5', 'QD333_6', 'UBIGEO', 'V022', 'V005', 'V190', 'V191', 'mujeres12a49', 'NCONGLOME']\n",
      "N° of variables of selected columns 22\n",
      "N° of variables of excluded columns 83\n"
     ]
    }
   ],
   "source": [
    "# Now, we can check the columns that are not included (for \"rec1_1\" case):\n",
    "# List of columns to exclude\n",
    "selected = [\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \n",
    "                      \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\"]\n",
    "columns_not_included = [col for col in rec_1.columns if col not in selected]    # list of columns that are not included\n",
    "\n",
    "print(columns_not_included)\n",
    "# We can corroborate this by viewing len()\n",
    "print(\"N° of variables of selected columns\",len(selected))\n",
    "print(\"N° of variables of excluded columns\", len(columns_not_included))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('ID1', 'Año'), ('HHID', 'Identificación Cuestionario del Hogar'), ('CASEID', 'Identificación Cuestionario Individual'), ('V001', 'Conglomerado'), ('V002', 'Número de vivienda'), ('V003', 'Número de línea de entrevistada'), ('V004', 'Unidad de área final'), ('V007', 'Año de la entrevista'), ('V008', 'Fecha de la entrevista, Codificación centenaria de meses (CMC)'), ('V009', 'Mes de nacimiento de la entrevistada'), ('V010', 'Año de nacimiento de la entrevistada'), ('V011', 'Fecha de nacimiento, Codificación centenaria de meses (CMC)'), ('V012', 'Edad actual - entrevistada'), ('V013', 'Edad actual por grupos de 5 años'), ('V014', 'Integridad de la información para la fecha de nacimiento'), ('V015', 'Resultado entrevista individual'), ('V017', 'Inicio del calendario, Codificación centenaria de mesesl CMC'), ('V018', 'Columna del mes de la entrevista'), ('V019', 'Duración del calendario'), ('V019A', 'Número de columnas de calendario'), ('V020', 'Muestra alguna vez casada'), ('V021', 'Unidad de muestreo primario - conglomerado'), ('V023', 'Dominio de ejemplo - Departamento'), ('V024', 'Región'), ('V025', 'Tipo de lugar de residencia'), ('V026', 'El lugar de residencia en el que se entrevistó - De Facto'), ('V027', 'Número de visitas'), ('V028', 'Identificación del entrevistador'), ('V029', 'Identificador del digitador'), ('V030', 'Supervisor de campo'), ('V031', 'Editor de campo'), ('V032', 'Editor de la oficina'), ('V033', 'Selección final del área de probabilidad'), ('V034', 'Número de orden del esposo'), ('V040', 'Altitud del conglomerado en metros'), ('V042', 'Selección de hogar para hemoglobina'), ('V043', 'Selección para módulo de estatus de mujeres'), ('V044', 'Selección para módulo de violencia domestica'), ('V000', 'Código y fase del país'), ('Q105DD', 'Dia de nacimeinto de la entrevistada'), ('V101', 'Región'), ('V102', 'Tipo de lugar de residencia'), ('V103', 'Lugar de residencia de la infancia'), ('V104', 'Cuanto tiempo tiene viviendo continuamente en el lugar de residencia actual'), ('V105', 'Tipo de lugar de residencia anteriormente'), ('V106', 'Nivel educativo más alto'), ('V107', 'Año/grado de educación más alto aprobado'), ('V113', 'Fuente principal de abasteciemiento de agua potable que utilizan en su hogar para tomar o beber'), ('V115', 'Tiempo para llegar a la fuente de agua'), ('V116', 'Tipo de instalación sanitaria'), ('V119', 'En su hogar tiene: electricidad'), ('V120', 'En su hogar tiene: radio'), ('V121', 'En su hogar tiene: televisión'), ('V122', 'En su hogar tiene: refrigerador'), ('V123', 'En su hogar tiene: bicicleta'), ('V124', 'En su hogar tiene: motocicleta/motocar'), ('V125', 'En su hogar tiene: coche/camión'), ('V127', 'Material predominante del piso de la vivienda'), ('V128', 'Material predominante de las paredes exteriores de la vivienda'), ('V129', 'Material predominante del techo de la vivienda'), ('V130', 'Religión'), ('V131', 'Etnicidad'), ('V133', 'Educación en años simples'), ('V134', 'El lugar en el que se realizó la entrevista  De-facto'), ('V135', 'Residente habitual o visitante'), ('V136', 'Número de miembros del hogar'), ('V137', 'Número de niños de 6 años de edad'), ('V138', 'Número de mujeres de 15 a 49 años de edad elegibles en el hogar'), ('V139', 'Región, residencia habitual De-jure'), ('V140', 'Tipo de área de residencia De-jure'), ('V141', 'Lugar de residencia De-jure'), ('V149', 'Logro educativo'), ('V150', 'Relación con el jefe del hogar'), ('V151', 'Sexo del Jefe del Hogar'), ('V152', 'Edad del jefe del hogar'), ('V153', 'En su hogar tiene: teléfono'), ('AWFACTT', 'Factor todas las mujeres - total'), ('AWFACTU', 'Factor todas las mujeres - urbano/rural'), ('AWFACTR', 'Factor todas las mujeres - regional'), ('AWFACTE', 'Factor todas las mujeres - educación'), ('AWFACTW', 'Factor todas las mujeres - índice de riqueza'), ('V155', 'Alfabetización'), ('V156', 'Alguna vez participó en un programa de alfabetización (no incluyendo la escuela primaria)'), ('V157', 'Frecuencia de lectura de un periódico o revista'), ('V158', 'Frecuencia de escuchar radio'), ('V159', 'Frecuencia de ver televisión'), ('V160', 'Baño compartido con otros hogares'), ('V161', 'Tipo de combustible para cocinar'), ('V166', 'Resultados de la prueba del yodo en la sal'), ('V167', 'Número de viajes en los últimos 12 meses'), ('V168', 'Afuera más de un mes en los últimos 12 meses'), ('ML101', 'Tipo de mosquitero que utilizo para dormir última noche'), ('QD333_1', 'Alguna dificultad o limitación permanente para ver, aún usando anteojos'), ('QD333_2', 'Alguna dificultad o limitación permanente para oir, aún usando audífonos'), ('QD333_3', 'Alguna dificultad o limitación permanente para hablar o comunicarse, aún usando la lengua de señas u otro'), ('QD333_4', 'Alguna dificultad o limitación permanente para moverse o caminar para usar brazos y/o piernas'), ('QD333_5', 'Alguna dificultad o limitación permanente para entender o aprender (concentrarse y recordarse)'), ('QD333_6', 'Alguna dificultad o limitación permanente para relacionarse con los demás, por sus pensamientos, sentimientos, emociones o conductas'), ('UBIGEO', 'Código de Ubicación Gegráfica'), ('V022', 'Estratos'), ('V005', 'Factor de ponderacion'), ('V190', 'Índice de riqueza'), ('V191', 'Factor de puntuación del índice de riqueza (5 decimales)'), ('mujeres12a49', 'Mujeres de 12 a 49 años de edad'), ('NCONGLOME', 'Número de Conglomerado (proveniente del marco)')])\n"
     ]
    }
   ],
   "source": [
    "# 2.2 We update the variables and value labels objects\n",
    "# 2.2.1 New variable label:\n",
    "# The code is an iterative process that will only retain the pairs (key and value) whose key is found on the selected columns (rec1_1, rec2_1, and rec3_1)\n",
    "# items() returns a view object that displays a list of dictionary's (key, value) tuple pairs\n",
    "print(var_labels1.items())\n",
    "#\n",
    "new_var_labels1 = {key: value for key, value in var_labels1.items() if key in list(rec1_1.columns)}    \n",
    "new_var_labels2 = {key: value for key, value in var_labels2.items() if key in list(rec2_1.columns)}\n",
    "new_var_labels3 = {key: value for key, value in var_labels3.items() if key in list(rec3_1.columns)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CASEID': 'Identificación Cuestionario Individual',\n",
       " 'V001': 'Conglomerado',\n",
       " 'V002': 'Número de vivienda',\n",
       " 'V003': 'Número de línea de entrevistada',\n",
       " 'V004': 'Unidad de área final',\n",
       " 'V007': 'Año de la entrevista',\n",
       " 'V008': 'Fecha de la entrevista, Codificación centenaria de meses (CMC)',\n",
       " 'V009': 'Mes de nacimiento de la entrevistada',\n",
       " 'V010': 'Año de nacimiento de la entrevistada',\n",
       " 'V011': 'Fecha de nacimiento, Codificación centenaria de meses (CMC)',\n",
       " 'V012': 'Edad actual - entrevistada',\n",
       " 'V024': 'Región',\n",
       " 'V000': 'Código y fase del país',\n",
       " 'V102': 'Tipo de lugar de residencia',\n",
       " 'V120': 'En su hogar tiene: radio',\n",
       " 'V121': 'En su hogar tiene: televisión',\n",
       " 'V122': 'En su hogar tiene: refrigerador',\n",
       " 'V123': 'En su hogar tiene: bicicleta',\n",
       " 'V124': 'En su hogar tiene: motocicleta/motocar',\n",
       " 'V125': 'En su hogar tiene: coche/camión',\n",
       " 'V127': 'Material predominante del piso de la vivienda',\n",
       " 'V133': 'Educación en años simples'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that we updated the variable labels\n",
    "new_var_labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2 New value label: the same procedure applies\n",
    "new_value_labels1 = {key: value for key, value in value_labels1.items() if key in list(rec1_1.columns)}\n",
    "new_value_labels2 = {key: value for key, value in value_labels2.items() if key in list(rec2_1.columns)}\n",
    "new_value_labels3 = {key: value for key, value in value_labels3.items() if key in list(rec3_1.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V024': {1.0: 'Amazonas',\n",
       "  2.0: 'Ancash',\n",
       "  3.0: 'Apurimac',\n",
       "  4.0: 'Arequipa',\n",
       "  5.0: 'Ayacucho',\n",
       "  6.0: 'Cajamarca',\n",
       "  7.0: 'Callao',\n",
       "  8.0: 'Cusco',\n",
       "  9.0: 'Huancavelica',\n",
       "  10.0: ' Huanuco',\n",
       "  11.0: ' Ica',\n",
       "  12.0: ' Junin',\n",
       "  13.0: ' La Libertad',\n",
       "  14.0: ' Lambayeque',\n",
       "  15.0: ' Lima',\n",
       "  16.0: ' Loreto',\n",
       "  17.0: ' Madre de Dios',\n",
       "  18.0: ' Moquegua',\n",
       "  19.0: ' Pasco',\n",
       "  20.0: ' Piura',\n",
       "  21.0: ' Puno',\n",
       "  22.0: ' San Martin',\n",
       "  23.0: ' Tacna',\n",
       "  24.0: ' Tumbes',\n",
       "  25.0: ' Ucayali'},\n",
       " 'V102': {1.0: 'Urbano', 2.0: 'Rural'},\n",
       " 'V120': {0.0: 'No', 1.0: 'Si', 7.0: 'No es residente habitual'},\n",
       " 'V121': {0.0: 'No', 1.0: 'Si', 7.0: 'No es residente habitual'},\n",
       " 'V122': {0.0: 'No', 1.0: 'Si', 7.0: 'No es residente habitual'},\n",
       " 'V123': {0.0: 'No', 1.0: 'Si', 7.0: 'No es residente habitual'},\n",
       " 'V124': {0.0: 'No', 1.0: 'Si', 7.0: 'No es residente habitual'},\n",
       " 'V125': {0.0: 'No', 1.0: 'Si', 7.0: 'No es residente habitual'},\n",
       " 'V127': {11.0: 'Tierra/arena',\n",
       "  21.0: 'Madera (entablados)',\n",
       "  31.0: 'Parquet o madera pulida',\n",
       "  32.0: 'Làminas asfálticas, vinílicos o similares',\n",
       "  33.0: 'Losetas, terrazos o similares',\n",
       "  34.0: 'Cemento/ladrillo',\n",
       "  96.0: 'Pona',\n",
       "  97.0: 'Otro(pona)'},\n",
       " 'V133': {97.0: 'Inconsistente'}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that we updated the value labels\n",
    "new_value_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
