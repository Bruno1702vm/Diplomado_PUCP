{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127c98aa",
   "metadata": {},
   "source": [
    "# Exploring with Pandas and SAV files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5af913",
   "metadata": {},
   "source": [
    "1. Explore Endes `RECH1.SAV` file. It is located in this path `Diplomado_PUCP/_data/endes/2015/RECH1.SAV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427c5adb-dcc1-457b-a004-13aa23979301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\anaconda\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\anaconda\\lib\\site-packages (from pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f30b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a84ee096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "              HHID  HVIDX  HV101  HV102  HV103  HV104  HV105  HV106  HV107  \\\n",
      "0        000104301    3.0    3.0    1.0    1.0    1.0    2.0    0.0    NaN   \n",
      "1        000207901    5.0    3.0    1.0    1.0    1.0    0.0    0.0    NaN   \n",
      "2        000211901    4.0    3.0    1.0    1.0    1.0    3.0    0.0    NaN   \n",
      "3        000213001    5.0   10.0    1.0    1.0    1.0    2.0    0.0    NaN   \n",
      "4        000218601    2.0    3.0    1.0    1.0    1.0    3.0    0.0    NaN   \n",
      "\n",
      "   HV108  ...  HV137  HV138  HV139  HV140  QH13A1  QH13A2  QH13A3  QH13A4  \\\n",
      "0    0.0  ...    NaN    NaN    NaN    NaN     2.0     2.0     2.0     2.0   \n",
      "1    0.0  ...    NaN    NaN    NaN    NaN     2.0     2.0     2.0     2.0   \n",
      "2    0.0  ...    NaN    NaN    NaN    NaN     2.0     2.0     2.0     2.0   \n",
      "3    0.0  ...    NaN    NaN    NaN    NaN     2.0     2.0     2.0     2.0   \n",
      "4    0.0  ...    NaN    NaN    NaN    NaN     2.0     2.0     2.0     2.0   \n",
      "\n",
      "   QH13A5  QH13A6  \n",
      "0     2.0     2.0  \n",
      "1     2.0     2.0  \n",
      "2     2.0     2.0  \n",
      "3     2.0     2.0  \n",
      "4     2.0     2.0  \n",
      "\n",
      "[5 rows x 47 columns]\n",
      "\n",
      "Metadata:\n",
      "<pyreadstat._readstat_parser.metadata_container object at 0x00000189F3DF9D30>\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# Replace 'your_file.sav' with the path to your SPSS file\n",
    "file_path = r\"C:\\Users\\cesar\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2015\\RECH1.SAV\"\n",
    "\n",
    "# Read the SPSS file\n",
    "df, meta = pyreadstat.read_sav(file_path)\n",
    "\n",
    "# Display the data\n",
    "print(\"Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the metadata\n",
    "print(\"\\nMetadata:\")\n",
    "print(meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7016fbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HV101': {1.0: 'Head',\n",
       "  2.0: 'Wife or husband',\n",
       "  3.0: 'Son/daughter',\n",
       "  4.0: 'Son/daughter-in-law',\n",
       "  5.0: 'Grandchild',\n",
       "  6.0: 'Parent',\n",
       "  7.0: 'Parent-in-law',\n",
       "  8.0: 'Brother/sister',\n",
       "  9.0: 'Co-spouse',\n",
       "  10.0: 'Other relative',\n",
       "  11.0: 'Adopted/foster child',\n",
       "  12.0: 'Not related',\n",
       "  13.0: 'Niece/nehew by blood',\n",
       "  14.0: 'Niece/nephew by marriage',\n",
       "  15.0: 'Maid',\n",
       "  98.0: 'DK'},\n",
       " 'HV102': {0.0: 'No', 1.0: 'Yes'},\n",
       " 'HV103': {0.0: 'No', 1.0: 'Yes'},\n",
       " 'HV104': {1.0: 'Male', 2.0: 'Female'},\n",
       " 'HV105': {97.0: '97+', 98.0: 'DK'},\n",
       " 'HV106': {0.0: 'No education, preschool',\n",
       "  1.0: 'Primary',\n",
       "  2.0: 'Secondary',\n",
       "  3.0: 'Higher',\n",
       "  8.0: 'DK'},\n",
       " 'HV107': {98.0: 'DK'},\n",
       " 'HV108': {97.0: 'Inconsistent', 98.0: 'DK'},\n",
       " 'HV109': {0.0: 'No education',\n",
       "  1.0: 'Incomplete primary',\n",
       "  2.0: 'Complete primary',\n",
       "  3.0: 'Incomplete secondary',\n",
       "  4.0: 'Complete secondary',\n",
       "  5.0: 'Higher',\n",
       "  8.0: 'DK'},\n",
       " 'HV110': {0.0: 'No', 1.0: 'Yes'},\n",
       " 'HV111': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV112': {0.0: 'Mother not in HH'},\n",
       " 'HV113': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV114': {0.0: 'Father not in HH'},\n",
       " 'HV115': {0.0: 'Never married',\n",
       "  1.0: 'Married',\n",
       "  2.0: 'Living together',\n",
       "  3.0: 'Widowed',\n",
       "  4.0: 'Divorced',\n",
       "  5.0: 'Not living together'},\n",
       " 'HV116': {0.0: 'Never married',\n",
       "  1.0: 'Currently married',\n",
       "  2.0: 'Formerly/ever marr.'},\n",
       " 'HV117': {0.0: 'Not eligible', 1.0: 'Eligible'},\n",
       " 'HV118': {0.0: 'Not eligible', 1.0: 'Eligible'},\n",
       " 'HV120': {0.0: 'Not eligible', 1.0: 'Eligible'},\n",
       " 'HV121': {0.0: 'No',\n",
       "  1.0: 'Currently attending',\n",
       "  2.0: 'Attended at some time'},\n",
       " 'HV122': {0.0: 'No education, preschool',\n",
       "  1.0: 'Primary',\n",
       "  2.0: 'Secondary',\n",
       "  3.0: 'Higher',\n",
       "  8.0: 'DK'},\n",
       " 'HV123': {98.0: 'DK'},\n",
       " 'HV124': {97.0: 'Inconsistent', 98.0: 'DK'},\n",
       " 'HV125': {0.0: 'No', 1.0: 'Yes'},\n",
       " 'HV126': {0.0: 'No education, preschool',\n",
       "  1.0: 'Primary',\n",
       "  2.0: 'Secondary',\n",
       "  3.0: 'Higher',\n",
       "  8.0: 'DK'},\n",
       " 'HV127': {98.0: 'DK'},\n",
       " 'HV128': {97.0: 'Inconsistent', 98.0: 'DK'},\n",
       " 'HV129': {0.0: 'Never attended',\n",
       "  1.0: 'Entered school',\n",
       "  2.0: 'Advanced',\n",
       "  3.0: 'Repeating',\n",
       "  4.0: 'Dropout',\n",
       "  5.0: 'Left school 2+ years ago',\n",
       "  8.0: 'DK'},\n",
       " 'HV130': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV131': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV132': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV133': {0.0: 'No', 1.0: 'Yes'},\n",
       " 'HV134': {0.0: 'No', 1.0: 'Yes'},\n",
       " 'HV135': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV136': {0.0: 'No', 1.0: 'Yes'},\n",
       " 'HV137': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV138': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV139': {0.0: 'No', 1.0: 'Yes', 8.0: 'DK'},\n",
       " 'HV140': {0.0: 'Neither certificate or registered',\n",
       "  1.0: 'Has certificate',\n",
       "  2.0: 'Registered',\n",
       "  8.0: 'DK'},\n",
       " 'QH13A1': {1.0: 'Si', 2.0: 'No', 8.0: 'No sabe'},\n",
       " 'QH13A2': {1.0: 'Si', 2.0: 'No', 8.0: 'No sabe'},\n",
       " 'QH13A3': {1.0: 'Si', 2.0: 'No', 8.0: 'No sabe'},\n",
       " 'QH13A4': {1.0: 'Si', 2.0: 'No', 8.0: 'No sabe'},\n",
       " 'QH13A5': {1.0: 'Si', 2.0: 'No', 8.0: 'No sabe'},\n",
       " 'QH13A6': {1.0: 'Si', 2.0: 'No', 8.0: 'No sabe'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.variable_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baddef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HHID': 'Case Identification',\n",
       " 'HVIDX': 'Line number',\n",
       " 'HV101': 'Relationship to head',\n",
       " 'HV102': 'Usual resident',\n",
       " 'HV103': 'Slept last night',\n",
       " 'HV104': 'Sex of household member',\n",
       " 'HV105': 'Age of household members',\n",
       " 'HV106': 'Highest educational level',\n",
       " 'HV107': 'Highest year of education',\n",
       " 'HV108': 'Education in single years',\n",
       " 'HV109': 'Educational attainment',\n",
       " 'HV110': 'Member still in school',\n",
       " 'HV111': 'Mother alive',\n",
       " 'HV112': \"Mother's line number\",\n",
       " 'HV113': 'Father alive',\n",
       " 'HV114': \"Father's line number\",\n",
       " 'HV115': 'Current marital status',\n",
       " 'HV116': 'Currently, formerly, never m.',\n",
       " 'HV117': 'Eligibility for female interview',\n",
       " 'HV118': 'Eligibility for male interview',\n",
       " 'HV120': 'Children eligibility for height/weight and hemoglobin',\n",
       " 'HV121': 'Member attended school during current school year',\n",
       " 'HV122': 'Educational level during current school year',\n",
       " 'HV123': 'Grade of education during current school year',\n",
       " 'HV124': 'Education in single years - current school year',\n",
       " 'HV125': 'Member attended school during previous school year',\n",
       " 'HV126': 'Educational level during previous school year',\n",
       " 'HV127': 'Grade of education during previous school year',\n",
       " 'HV128': 'Education in single years - previous school year',\n",
       " 'HV129': 'School attendance status',\n",
       " 'HV130': 'Member has been very sick for 3+ months last year',\n",
       " 'HV131': 'Mother has been very sick for 3+ months last year',\n",
       " 'HV132': 'Father has been very sick for 3+ months last year',\n",
       " 'HV133': 'Mother/father dead or been very sick for 3+ months',\n",
       " 'HV134': 'Both parents alive',\n",
       " 'HV135': 'Has brothers/sisters under 18 of the same father and mother',\n",
       " 'HV136': \"Brothers/sisters under 18 that don't live in household\",\n",
       " 'HV137': 'Member has a blanket',\n",
       " 'HV138': 'Member has a pair of shoes',\n",
       " 'HV139': 'Member has 2+ sets of clothes',\n",
       " 'HV140': 'Member has a birth certificate',\n",
       " 'QH13A1': 'Limitacion permanente para moverse',\n",
       " 'QH13A2': 'Limitacion permanente para ver',\n",
       " 'QH13A3': 'Limitacion permanente para oir',\n",
       " 'QH13A4': 'Limitacion permanente para hablar',\n",
       " 'QH13A5': 'Limitacion permanente para entender',\n",
       " 'QH13A6': 'Limitacion permanenete para relacionarse'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.column_names_to_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac826ef",
   "metadata": {},
   "source": [
    "2. Import all the RECH1.SAV files from all the subfolder located in this folder. `Diplomado_PUCP/_data/endes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaade26",
   "metadata": {},
   "source": [
    "Doing one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(2015, 2020)\n",
    "\n",
    "df2015 = pd.read_spss(r\"C:\\Users\\cesar\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2015\\RECH1.SAV\")  #usar la ruta relativa\n",
    "\n",
    "df2015.loc[ :, 'year_sample'] = 2015\n",
    "\n",
    "df2016 = pd.read_spss(r\"C:\\Users\\cesar\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2016\\RECH1.SAV\")\n",
    "\n",
    "df2016.loc[ :, 'year_sample'] = 2016\n",
    "\n",
    "df2017 = pd.read_spss(r\"C:\\Users\\cesar\\Documents\\GitHub\\Diplomado_PUCP\\_data\\endes\\2017\\RECH1.SAV\")\n",
    "\n",
    "df2017.loc[ :, 'year_sample'] = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b674ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append data\n",
    "df_app = pd.concat([df2015, df2016, df2017]) #appendiar significa poner una base de datos debajo de otra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba5507",
   "metadata": {},
   "source": [
    "Using a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e36bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "years = np.arange(2015, 2020)\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    file_path = f'/Users/ar8787/Documents/GitHub/Diplomado_PUCP/_data/endes/{year}/RECH1.SAV'\n",
    "    df = pd.read_spss(file_path)\n",
    "    df['year_sample'] = year\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames for different years into a single DataFrame\n",
    "result_df = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b00b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2678e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89417a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "# If you need to read .SAV files, you might need a library like pyreadstat\n",
    "import pyreadstat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d11a1f2",
   "metadata": {},
   "source": [
    "Step 3: Navigating Directories and Finding Files\n",
    "You can use os and glob libraries to navigate through directories and find files. Here's a basic way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sav_files(base_path):\n",
    "    # This pattern will match any RECH1.SAV files in subdirectories of the base path\n",
    "    pattern = os.path.join(base_path, '**', 'RECH1.SAV')\n",
    "    \n",
    "    # glob.glob will return a list of file paths matching the pattern\n",
    "    # recursive=True allows searching in subdirectories\n",
    "    return glob.glob(pattern, recursive=True)\n",
    "\n",
    "base_path = 'Diplomado_PUCP/_data/endes'\n",
    "sav_files = find_sav_files(base_path)\n",
    "print(\"Found .SAV files:\", sav_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec2bd4",
   "metadata": {},
   "source": [
    "Step 4: Reading .SAV Files\n",
    "If you need to read data from these .SAV files, you can use pyreadstat. Here's a simple way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aece45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sav_file(file_path):\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "    return df  # df is a DataFrame containing the data from the .SAV file\n",
    "\n",
    "# Example of reading the first found .SAV file\n",
    "if sav_files:\n",
    "    first_file_data = read_sav_file(sav_files[0])\n",
    "    print(first_file_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605c783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c44c47",
   "metadata": {},
   "source": [
    "1. We have data `MotherData.csv` excerpted from a recent Demographic and Health Survey.  First convert the dataset from `wide` (each observation is a mother) to `long` (each observation is a birth, with associated mother id). The id `caseid` identifies uniquely all the mothers.  These columns refer to variable of children **['bidx', 'bord', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9', 'b10', 'b11', 'b12', 'b13', 'b15', 'b16']** and have new columns for all their children. We have information for 20 children. It starts from last child to oldest one. Use for loops to reshape this dataset from `wide` to `long` ate mother and children level. If you want to get more information from the columns please see [this pdf](http://www.dhsprogram.com/pubs/pdf/DHSG4/Recode6_DHS_22March2013_DHSG4.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb18668",
   "metadata": {},
   "source": [
    "Max number of children is 20. We want data at mother, child level. From children, we only want month (b1) and year (b2) of birth (b4), and sex and have data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa92823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r4/lwrzx5hs7d3cxk4p5zsy7zqh0000gp/T/ipykernel_27652/1107978888.py:1: DtypeWarning: Columns (67,128,129,130,131,132,133,208,209,210,211,212,213,228,229,230,231,232,233,240,241,245,247,248,249,250,308,309,310,311,312,313,328,329,330,331,332,333,387,388,389,390,391,392,407,408,409,410,411,412,426,428,429,430,431,433) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_mother = pd.read_csv('../_data/MotherData.csv')\n"
     ]
    }
   ],
   "source": [
    "df_mother = pd.read_csv('../_data/MotherData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47658cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                caseid  bord    b1      b2      b4\n",
      "0           1  1     2   7.0   3.0  2010.0    male\n",
      "1           1  1     2   6.0  11.0  2006.0  female\n",
      "2           1  1     2   5.0   1.0  2004.0  female\n",
      "3           1  1     2   4.0   3.0  1999.0  female\n",
      "4           1  1     2   3.0   6.0  1996.0  female\n",
      "...                ...   ...   ...     ...     ...\n",
      "19639     240 23     2   1.0   6.0  2007.0  female\n",
      "19640     240 24     2   4.0  10.0  2010.0    male\n",
      "19641     240 24     2   3.0  12.0  2007.0    male\n",
      "19642     240 24     2   2.0   9.0  2005.0    male\n",
      "19643     240 24     2   1.0   7.0  2000.0    male\n",
      "\n",
      "[19644 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "reshaped_data = []\n",
    "# Iterate through each row in the dataframe\n",
    "for index, row in df_mother.iterrows():\n",
    "    caseid = row['caseid']\n",
    "    # Iterate over the 20 sets of columns\n",
    "    for i in range(1, 21):\n",
    "        bord_col = f'bord_{i:02d}'\n",
    "        b1_col = f'b1_{i:02d}'\n",
    "        b2_col = f'b2_{i:02d}'\n",
    "        b4_col = f'b4_{i:02d}'\n",
    "        \n",
    "        # Check if bord_col is NaN, and if so, continue to the next iteration\n",
    "        if pd.isna(row[bord_col]):\n",
    "            continue\n",
    "        \n",
    "        # Append the reshaped row to the list\n",
    "        reshaped_data.append({\n",
    "            'caseid': caseid,\n",
    "            'bord': row[bord_col],\n",
    "            'b1': row[b1_col],\n",
    "            'b2': row[b2_col],\n",
    "            'b4': row[b4_col]\n",
    "        })\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "reshaped_df_mother = pd.DataFrame(reshaped_data)\n",
    "print(reshaped_df_mother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e58efec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>bord</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19639</th>\n",
       "      <td>240 23     2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19643</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19642</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19641</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19640</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                caseid  bord    b1      b2      b4\n",
       "6           1  1     2   1.0  11.0  1987.0  female\n",
       "5           1  1     2   2.0   6.0  1993.0  female\n",
       "4           1  1     2   3.0   6.0  1996.0  female\n",
       "3           1  1     2   4.0   3.0  1999.0  female\n",
       "2           1  1     2   5.0   1.0  2004.0  female\n",
       "...                ...   ...   ...     ...     ...\n",
       "19639     240 23     2   1.0   6.0  2007.0  female\n",
       "19643     240 24     2   1.0   7.0  2000.0    male\n",
       "19642     240 24     2   2.0   9.0  2005.0    male\n",
       "19641     240 24     2   3.0  12.0  2007.0    male\n",
       "19640     240 24     2   4.0  10.0  2010.0    male\n",
       "\n",
       "[19644 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_df_mother.sort_values( ['caseid', 'bord' ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c575478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use pandas wide_to_long function\n",
    "df_mother_long = pd.wide_to_long(df_mother, stubnames=['bord', 'b1', 'b2', 'b4'], i='caseid', j='index', sep='_', suffix='\\\\d+')\n",
    "\n",
    "# Reset the index to get a flat dataframe\n",
    "df_mother_long = df_mother_long.reset_index()\n",
    "\n",
    "# Drop rows where 'bord' is NaN\n",
    "df_mother_long = df_mother_long.dropna(subset=['bord'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a648bf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>bord</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38064</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31720</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25376</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19032</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12688</th>\n",
       "      <td>1  1     2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>240 23     2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25374</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19030</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12686</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6342</th>\n",
       "      <td>240 24     2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                caseid  bord    b1      b2      b4\n",
       "38064       1  1     2   1.0  11.0  1987.0  female\n",
       "31720       1  1     2   2.0   6.0  1993.0  female\n",
       "25376       1  1     2   3.0   6.0  1996.0  female\n",
       "19032       1  1     2   4.0   3.0  1999.0  female\n",
       "12688       1  1     2   5.0   1.0  2004.0  female\n",
       "...                ...   ...   ...     ...     ...\n",
       "6341      240 23     2   1.0   6.0  2007.0  female\n",
       "25374     240 24     2   1.0   7.0  2000.0    male\n",
       "19030     240 24     2   2.0   9.0  2005.0    male\n",
       "12686     240 24     2   3.0  12.0  2007.0    male\n",
       "6342      240 24     2   4.0  10.0  2010.0    male\n",
       "\n",
       "[19644 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mother_long.loc[ :, ['caseid', 'bord', 'b1', 'b2', 'b4']].sort_values( ['caseid', 'bord' ] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
